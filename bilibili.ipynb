{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> 视频播放量预测：多种特征的综合分析</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1 案例目标**\n",
    "\n",
    "如何利用视频的封面与标题建立模型预测视频播放量。我们希望训练一个模型，使得当我们输入视频的封面和标题后，模型能输出预测的视频播放量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **2 基本思路**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的思路是：\n",
    "\n",
    "- （1）将视频封面图片经过迁移学习，变成一个图像特征X向量；\n",
    "\n",
    "具体而言将封面图片输入模型后，经过卷积神经网络（砍掉全连接层后的）进行图片特征的提取，得到图像特征X\n",
    "\n",
    "- （2）将标题文本通过编码处理，变成一个文本特征X向量；\n",
    "\n",
    "使用Tokenizer对标题文本进行编码处理，得到文本特征X\n",
    "\n",
    "- （3）将播放量作为Y向量，基于X，Y，建立一个LSTM回归模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 案例背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "哔哩哔哩（简称B站），从最初围绕ACG文化的视频网站到现在开辟了20多个视频分区的文化娱乐社区，它不断成长演变并吸引了无数年轻人聚集于此，目前平均月度活跃用户已超过2亿。\n",
    "对于B站上的视频创作者（UP主）而言，高播放量的视频除了能收获众多粉丝外，还能够吸引广告商与之合作从而变现。因此，提高视频的播放量至关重要。严格来说，视频的播放量受诸多因素的影响：从稿件自身来看，有封面与标题的吸引度、内容质量等因素；从传播角度，有观众分享次数、用户是否关注该UP主甚至B站自身推荐系统等因素。\n",
    "\n",
    "<div>\n",
    "<img src = \"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fi0.hdslb.com%2Fbfs%2Farticle%2F644819b882a576bb4cb91866d870a71f269719f8.png&refer=http%3A%2F%2Fi0.hdslb.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1648194290&t=5dcfe9acad3ac020b16bc90cdc63f1dd\">\n",
    "</div>\n",
    "\n",
    "在所有影响因素中，封面与标题是影响播放量的最重要因素之一。一方面，用户进入B站后映入眼帘的首先是视频与封面，而一个视频的标题和封面往往直接影响用户是否点击此视频；另一方面，其他因素如用户分享次数和推荐系统是否推荐与视频发布后第一批观众是否点击播放有关，而第一批观众是否点击播放同样与封面和标题是否吸引人有很大关系。因此，本案例选择分别根据视频的封面与标题对播放量进行预测。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Images', 'master.csv', '.ipynb_checkpoints']\n",
      "74185\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('data'))                          #展示数据目录结构\n",
    "img_list=os.listdir('data/Images/')                #所有分析用图片文件名\n",
    "N=len(img_list); print(N)                          #图片总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>title</th>\n",
       "      <th>follower</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208204291</td>\n",
       "      <td>富奶奶vs穷奶奶/奶奶大战!</td>\n",
       "      <td>25907</td>\n",
       "      <td>5864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208212579</td>\n",
       "      <td>兄弟才是隐藏的boss啊</td>\n",
       "      <td>22</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208215972</td>\n",
       "      <td>你到底说还是不说…</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208219537</td>\n",
       "      <td>中国朋友教了我一句话：无事献殷勤，非奸即盗。</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208237322</td>\n",
       "      <td>如果你是大学里唯一的美人鱼！潜伏技巧！</td>\n",
       "      <td>25907</td>\n",
       "      <td>6357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74180</th>\n",
       "      <td>890997016</td>\n",
       "      <td>吃我邪神酱飞T</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74181</th>\n",
       "      <td>890997066</td>\n",
       "      <td>《和暗恋女神的厕所之情》</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74182</th>\n",
       "      <td>890997085</td>\n",
       "      <td>串哥和秀文一起连麦选妃</td>\n",
       "      <td>116</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74183</th>\n",
       "      <td>890997096</td>\n",
       "      <td>我又双叒叕来了</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74184</th>\n",
       "      <td>890997102</td>\n",
       "      <td>丈母娘啊，还是你最疼我啊！</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74185 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aid                   title  follower  view\n",
       "0      208204291          富奶奶vs穷奶奶/奶奶大战!     25907  5864\n",
       "1      208212579            兄弟才是隐藏的boss啊        22   125\n",
       "2      208215972               你到底说还是不说…        19     2\n",
       "3      208219537  中国朋友教了我一句话：无事献殷勤，非奸即盗。        47     3\n",
       "4      208237322     如果你是大学里唯一的美人鱼！潜伏技巧！     25907  6357\n",
       "...          ...                     ...       ...   ...\n",
       "74180  890997016                 吃我邪神酱飞T         2     1\n",
       "74181  890997066            《和暗恋女神的厕所之情》         0    78\n",
       "74182  890997085             串哥和秀文一起连麦选妃       116   275\n",
       "74183  890997096                 我又双叒叕来了         0     3\n",
       "74184  890997102           丈母娘啊，还是你最疼我啊！         0     3\n",
       "\n",
       "[74185 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "master = pd.read_csv('data/master.csv')             # 读取master信息文件\n",
    "master                                              # 展示部分数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "视频信息文件中各变量含义：\n",
    "\n",
    "* aid: 视频（图片）编号\n",
    "* title: 视频标题\n",
    "* follower: 发布者粉丝数\n",
    "* view: 视频播放量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制播放量直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "master['log_view'] = master['view'].apply(lambda x:np.log(x+1))          # 对播放量取对数，记为‘log_view’\n",
    "master['log_view'] = master['log_view']-np.mean(master['log_view'])      # 对播放量中心化\n",
    "master['log_view'] = master['log_view']/np.std(master['log_view'])       # 对播放量标准化\n",
    "\n",
    "plt.hist(master['log_view'])                                             # 对数标准化后播放量直方图\n",
    "plt.xlabel(\"log(view+1)\")                                                # 添加x轴标签\n",
    "plt.show()                                                               # 显示图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 图像数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们通过**迁移学习**提取图片特征。具体而言，通过迁移MobileNet模型并截断最后一层输出层，将每一个图片转换转换成1024维的特征X。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "dx=128;dy=128                                             #确定图片尺寸\n",
    "N = master.shape[0]                                       #全样本量\n",
    "n = 3*10**3                                               #教学需要，确定一个不要太大的样本量\n",
    "img_list=[]                                               #初始化一个list用于存储图像数据\n",
    "cap_list=[]                                               #初始化一个list用于存储图像的文字标注\n",
    "follower_list=[]                                          #初始化一个list用于存储粉丝数目\n",
    "view_list=[]                                              #初始化一个list用于存储播放量（对数标准化后）\n",
    "for i in range(n):\n",
    "    pos=np.random.randint(0,N)                            #随机抽取一个图片\n",
    "    cap_list.append(master.title[pos])                    #记录图片描述用文字\n",
    "    follower_list.append(np.log(1+master.follower[pos]))  #记录相关粉丝人数\n",
    "    view_list.append(master.log_view[pos])                #记录播放量\n",
    "    pic=master.aid[pos]                                   #被选中的图片的ID\n",
    "    Img=Image.open('data/Images/'+str(pic)+'.jpg')        #读入图像数据\n",
    "    img_list.append(np.array(Img.resize([dx,dy]))/255)    #记录选中的图片\n",
    "\n",
    "imgs=np.array(img_list)                                   #形成数组\n",
    "followers=np.array(follower_list).reshape([n,1])          #形成数组  \n",
    "views=np.array(view_list).reshape([n,1])                  #形成数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 08:04:43.224231: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-16 08:04:44.103943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14264 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:04:00.0, compute capability: 8.6\n",
      "2024-04-16 08:04:46.727580: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2024-04-16 08:04:49.045103: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,BatchNormalization\n",
    "\n",
    "base_model = MobileNet( weights='imagenet',                                       # 加载经过训练的MobileNet模型的权重\n",
    "                        include_top=False,                                        # 不包含顶端\n",
    "                        input_shape=(dx, dy, 3))                                  # 输入图片的大小为 128*128*3\n",
    "x = base_model.output                                                             # 由迁移的MobileNet模型提取图片特征\n",
    "predict = GlobalAveragePooling2D()(x)                                             # 添加全局平均池化层\n",
    "model = Model(inputs=base_model.input, outputs=predict)                           # 构建需要训练的完整模型\n",
    "for layer in base_model.layers: layer.trainable = False                           # 锁住MobileNet的所有层（不进行训练）\n",
    "imgs=np.array(model(imgs))                                                        # 形成相关的X特征矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 文本数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于文字是非结构化数据，不能在计算机中直接分析，因此对文字进行编码处理。\n",
    "具体而言，使用Tokenizer建立分词器，根据词频，将每个文本转化为一个整数序列（每个整数都是词典中标记的索引），得到文本数组X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.843 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba                                 # 导入jieba包\n",
    "caps = []                                    # 新建一个空的列表，用于储存训练数据\n",
    "long_list=[]                                 # 创建一个特别长的list用于存储所有的分词结果\n",
    "for line in cap_list:                        # 遍历每一个标题\n",
    "    line_fenci = jieba.lcut(line)            # 对标题进行分词\n",
    "    caps.append(line_fenci)                  # 将分词后的结果添加到列表中\n",
    "    long_list=long_list+line_fenci           # 创建一个特别长的list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算各个关键词的频数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "skip_list=[',','!','：','《','》','!','?','(',')','，','【','】','（','）','！','？','，','。','#',' ','.']\n",
    "long_list=[each for each in long_list if each not in skip_list]\n",
    "long_list=[each for each in long_list if len(each)>1]\n",
    "tab=Counter(long_list)\n",
    "keys=[each[0] for each in tab.items() if int(each[1])>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新整理标题描述文本的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_list_new=[]\n",
    "for each in caps: cap_list_new.append([kw for kw in each if kw in keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对新的文字关键词形成编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()                                            #产生一个分词器对象\n",
    "tokenizer.fit_on_texts(cap_list_new)                               #用标题的文本训练分词器\n",
    "cap_digit = tokenizer.texts_to_sequences(cap_list_new)             #将每个视频标题的文本转化为序列（列表类型）。每个字通过一个数值表示，每个视频标题的文本即变为这样数值的序列\n",
    "vocab_size = len(tokenizer.word_index) + 1                         #tokenizer.word_index为所有的词，len(tokenizer.word_index)为词的总个数。加上停止词0\n",
    "vocab_size                                                         #有多少个不同的词\n",
    "caps = pad_sequences(cap_digit, maxlen=6,padding='post')          #为了将所有的标题放在一个尺寸M*N的np.array中，将每一个视频的标题补0到同样的长度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 建立一个综合的LSTM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1：全模型（图像+文本+粉丝数）\n",
    "\n",
    "对于模型1，我们的X为：图像特征，文本特征，以及粉丝数，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 6, 128)       39680       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          131200      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          131584      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 302,849\n",
      "Trainable params: 302,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 08:04:51.920983: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 10ms/step - loss: 21.1160 - mse: 21.1160\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 18.4458 - mse: 18.4458\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.3296 - mse: 7.3296\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.0959 - mse: 9.0959\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4683 - mse: 6.4683\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.2797 - mse: 4.2797\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.0110 - mse: 5.0110\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5723 - mse: 2.5723\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.5940 - mse: 3.5940\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1870 - mse: 2.1870\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.4873 - mse: 2.4873\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.9595 - mse: 1.9595\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.7563 - mse: 1.7563\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7624 - mse: 1.7624\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4915 - mse: 1.4915\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4873 - mse: 1.4873\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4064 - mse: 1.4064\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2847 - mse: 1.2847\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.2828 - mse: 1.2828\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1902 - mse: 1.1902\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1456 - mse: 1.1456\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1152 - mse: 1.1152\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0561 - mse: 1.0561\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0204 - mse: 1.0204\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0014 - mse: 1.0014\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9687 - mse: 0.9687\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9428 - mse: 0.9428\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9225 - mse: 0.9225\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8980 - mse: 0.8980\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8780 - mse: 0.8780\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8595 - mse: 0.8595\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8414 - mse: 0.8414\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8256 - mse: 0.8256\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8079 - mse: 0.8079\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7924 - mse: 0.7924\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7736 - mse: 0.7736\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7586 - mse: 0.7586\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7403 - mse: 0.7403\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7236 - mse: 0.7236\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7056 - mse: 0.7056\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6877 - mse: 0.6877\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6692 - mse: 0.6692\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6510 - mse: 0.6510\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6362 - mse: 0.6362\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6247 - mse: 0.6247\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6133 - mse: 0.6133\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6021 - mse: 0.6021\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5946 - mse: 0.5946\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5808 - mse: 0.5808\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5720 - mse: 0.5720\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5643 - mse: 0.5643\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5558 - mse: 0.5558\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5484 - mse: 0.5484\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5410 - mse: 0.5410\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5339 - mse: 0.5339\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5273 - mse: 0.5273\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5212 - mse: 0.5212\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5159 - mse: 0.5159\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5096 - mse: 0.5096\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5046 - mse: 0.5046\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4998 - mse: 0.4998\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4948 - mse: 0.4948\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4900 - mse: 0.4900\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4840 - mse: 0.4840\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4800 - mse: 0.4800\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4756 - mse: 0.4756\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4698 - mse: 0.4698\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4679 - mse: 0.4679\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4610 - mse: 0.4610\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4583 - mse: 0.4583\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4539 - mse: 0.4539\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4508 - mse: 0.4508\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4474 - mse: 0.4474\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4424 - mse: 0.4424\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4390 - mse: 0.4390\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4376 - mse: 0.4376\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4338 - mse: 0.4338\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4284 - mse: 0.4284\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4272 - mse: 0.4272\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4209 - mse: 0.4209\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4218 - mse: 0.4218\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4176 - mse: 0.4176\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4148 - mse: 0.4148\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4089 - mse: 0.4089\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4054 - mse: 0.4054\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4020 - mse: 0.4020\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3993 - mse: 0.3993\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3963 - mse: 0.3963\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3944 - mse: 0.3944\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3910 - mse: 0.3910\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3890 - mse: 0.3890\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3858 - mse: 0.3858\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3862 - mse: 0.3862\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3834 - mse: 0.3834\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3833 - mse: 0.3833\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3795 - mse: 0.3795\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3728 - mse: 0.3728\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3711 - mse: 0.3711\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3725 - mse: 0.3725\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3651 - mse: 0.3651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed07c47c40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Activation, Reshape,add\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "dim_img=imgs.shape[1]                                                 #维度：图像数组\n",
    "dim_follower=1                                                        #维度：粉丝数目\n",
    "dim_cap=caps.shape[1]                                                 #维度：文字描述\n",
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_img,x_cap,x_follower])                                       #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_img,inp_follower,inp_cap], x)                      #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([imgs,followers,caps], views, epochs=100, batch_size=1000)  #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型2：对比模型（文本+粉丝数）\n",
    "\n",
    "对于模型2，我们的X为：文本特征和粉丝数，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 6, 128)       39680       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          131584      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128)          0           lstm_1[0][0]                     \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 171,649\n",
      "Trainable params: 171,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 7ms/step - loss: 2.1926 - mse: 2.1926\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0928 - mse: 1.0928\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6537 - mse: 0.6537\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7645 - mse: 0.7645\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8060 - mse: 0.8060\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7002 - mse: 0.7002\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6348 - mse: 0.6348\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6300 - mse: 0.6300\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6464 - mse: 0.6464\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6530 - mse: 0.6530\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6425 - mse: 0.6425\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6265 - mse: 0.6265\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6160 - mse: 0.6160\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6137 - mse: 0.6137\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6123 - mse: 0.6123\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6074 - mse: 0.6074\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6005 - mse: 0.6005\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5956 - mse: 0.5956\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5938 - mse: 0.5938\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5910 - mse: 0.5910\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5872 - mse: 0.5872\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5839 - mse: 0.5839\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5808 - mse: 0.5808\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5771 - mse: 0.5771\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5721 - mse: 0.5721\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5672 - mse: 0.5672\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5621 - mse: 0.5621\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5673 - mse: 0.567 - 0s 6ms/step - loss: 0.5561 - mse: 0.5561\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5497 - mse: 0.5497\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5442 - mse: 0.5442\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5396 - mse: 0.5396\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5359 - mse: 0.5359\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5332 - mse: 0.5332\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5318 - mse: 0.5318\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5308 - mse: 0.5308\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5291 - mse: 0.5291\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5270 - mse: 0.5270\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5254 - mse: 0.5254\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5241 - mse: 0.5241\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5231 - mse: 0.5231\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5228 - mse: 0.5228\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5213 - mse: 0.5213\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5204 - mse: 0.5204\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5202 - mse: 0.5202\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5194 - mse: 0.5194\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5186 - mse: 0.5186\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5181 - mse: 0.5181\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5175 - mse: 0.5175\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5172 - mse: 0.5172\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5165 - mse: 0.5165\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5159 - mse: 0.5159\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5155 - mse: 0.5155\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5150 - mse: 0.5150\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5146 - mse: 0.5146\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5142 - mse: 0.5142\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5139 - mse: 0.5139\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5132 - mse: 0.5132\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5128 - mse: 0.5128\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5122 - mse: 0.5122\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5114 - mse: 0.5114\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5110 - mse: 0.5110\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5106 - mse: 0.5106\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5097 - mse: 0.5097\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5092 - mse: 0.5092\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5084 - mse: 0.5084\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5077 - mse: 0.5077\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5074 - mse: 0.5074\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5062 - mse: 0.5062\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5056 - mse: 0.5056\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5047 - mse: 0.5047\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5038 - mse: 0.5038\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5028 - mse: 0.5028\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5021 - mse: 0.5021\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5011 - mse: 0.5011\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4996 - mse: 0.4996\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4985 - mse: 0.4985\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4972 - mse: 0.4972\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4958 - mse: 0.4958\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4946 - mse: 0.4946\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4931 - mse: 0.4931\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4917 - mse: 0.4917\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4900 - mse: 0.4900\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4888 - mse: 0.4888\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4869 - mse: 0.4869\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4854 - mse: 0.4854\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4840 - mse: 0.4840\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4821 - mse: 0.4821\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4807 - mse: 0.4807\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4790 - mse: 0.4790\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4781 - mse: 0.4781\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4759 - mse: 0.4759\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4745 - mse: 0.4745\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4733 - mse: 0.4733\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4727 - mse: 0.4727\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4706 - mse: 0.4706\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4693 - mse: 0.4693\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4675 - mse: 0.4675\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4660 - mse: 0.4660\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4651 - mse: 0.4651\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4635 - mse: 0.4635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed07b28df0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_cap,x_follower])                                             #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_follower,inp_cap], x)                              #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([followers,caps], views, epochs=100, batch_size=1000)       #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 模型3：对比模型（图像+文本）\n",
    "\n",
    "对于模型3，我们的X为：图像特征和文本特征，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 6, 128)       39680       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          131200      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          131584      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128)          0           dense_6[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            129         add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 302,593\n",
      "Trainable params: 302,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 8ms/step - loss: 8.7605 - mse: 8.7605\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.2444 - mse: 6.2444\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.1948 - mse: 4.1948\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.6030 - mse: 3.6030\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.5756 - mse: 3.5756\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.8235 - mse: 2.8235\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.1957 - mse: 2.1957\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1232 - mse: 2.1232\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0840 - mse: 2.0840\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8219 - mse: 1.8219\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5951 - mse: 1.5951\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.5491 - mse: 1.5491\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5013 - mse: 1.5013\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4106 - mse: 1.4106\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3213 - mse: 1.3213\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2667 - mse: 1.2667\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2285 - mse: 1.2285\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2036 - mse: 1.2036\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1671 - mse: 1.1671\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1267 - mse: 1.1267\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0971 - mse: 1.0971\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0566 - mse: 1.0566\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.0035 - mse: 1.0035\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9690 - mse: 0.9690\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9360 - mse: 0.9360\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9099 - mse: 0.9099\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8993 - mse: 0.8993\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8729 - mse: 0.8729\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8500 - mse: 0.8500\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8272 - mse: 0.8272\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8176 - mse: 0.8176\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8037 - mse: 0.8037\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7836 - mse: 0.7836\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7727 - mse: 0.7727\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7599 - mse: 0.7599\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7539 - mse: 0.7539\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7433 - mse: 0.7433\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7288 - mse: 0.7288\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7186 - mse: 0.7186\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7094 - mse: 0.7094\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7016 - mse: 0.7016\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6941 - mse: 0.6941\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6851 - mse: 0.6851\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6780 - mse: 0.6780\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6721 - mse: 0.6721\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6766 - mse: 0.6766\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6651 - mse: 0.6651\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6700 - mse: 0.6700\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6611 - mse: 0.6611\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6518 - mse: 0.6518\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6375 - mse: 0.6375\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6332 - mse: 0.6332\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6298 - mse: 0.6298\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6219 - mse: 0.6219\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6223 - mse: 0.6223\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6081 - mse: 0.6081\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6000 - mse: 0.6000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5958 - mse: 0.5958\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5887 - mse: 0.5887\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5847 - mse: 0.5847\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5825 - mse: 0.5825\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5762 - mse: 0.5762\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5729 - mse: 0.5729\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5729 - mse: 0.5729\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5827 - mse: 0.5827\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5780 - mse: 0.5780\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5622 - mse: 0.5622\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5625 - mse: 0.5625\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5615 - mse: 0.5615\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5430 - mse: 0.5430\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5367 - mse: 0.5367\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5509 - mse: 0.5509\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5335 - mse: 0.5335\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5303 - mse: 0.5303\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5135 - mse: 0.5135\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5121 - mse: 0.5121\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5166 - mse: 0.5166\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5053 - mse: 0.5053\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5098 - mse: 0.5098\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4975 - mse: 0.4975\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4917 - mse: 0.4917\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4893 - mse: 0.4893\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4904 - mse: 0.4904\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4886 - mse: 0.4886\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4990 - mse: 0.4990\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4891 - mse: 0.4891\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4908 - mse: 0.4908\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4904 - mse: 0.4904\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5021 - mse: 0.5021\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4747 - mse: 0.4747\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4683 - mse: 0.4683\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4611 - mse: 0.4611\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4604 - mse: 0.4604\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4536 - mse: 0.4536\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4526 - mse: 0.4526\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4538 - mse: 0.4538\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4625 - mse: 0.4625\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4500 - mse: 0.4500\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4500 - mse: 0.4500\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4449 - mse: 0.4449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed07a729a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_img,x_cap])                                                  #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_img,inp_cap], x)                                   #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([imgs,caps], views, epochs=100, batch_size=1000)            #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型4：对比模型（图像+粉丝数）\n",
    "\n",
    "对于模型4，我们的X为：图像特征和粉丝数，Y为播放量。\n",
    "\n",
    "因此我们建立一个回归模型，建立模型后，进行模型编译和训练，这里我们选择的损失函数是'mse'，优化器是'adam'（学习率为0.001）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          131200      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          256         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            129         add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 131,585\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 24.7392 - mse: 24.7392\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 26.9509 - mse: 26.9509\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.8076 - mse: 7.8076\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 14.5696 - mse: 14.5696\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1787 - mse: 5.1787\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.9959 - mse: 7.9959\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5734 - mse: 3.5734\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9052 - mse: 4.9052\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8009 - mse: 2.8009\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2271 - mse: 3.2271\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2374 - mse: 2.2374\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3023 - mse: 2.3023\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9698 - mse: 1.9698\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7081 - mse: 1.7081\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7103 - mse: 1.7103\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4087 - mse: 1.4087\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5071 - mse: 1.5071\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2213 - mse: 1.2213\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3106 - mse: 1.3106\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1808 - mse: 1.1808\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1580 - mse: 1.1580\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1169 - mse: 1.1169\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0511 - mse: 1.0511\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0467 - mse: 1.0467\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9944 - mse: 0.9944\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9795 - mse: 0.9795\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9559 - mse: 0.9559\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9250 - mse: 0.9250\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9126 - mse: 0.9126\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8942 - mse: 0.8942\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8736 - mse: 0.8736\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8606 - mse: 0.8606\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8422 - mse: 0.8422\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8256 - mse: 0.8256\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8128 - mse: 0.8128\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7976 - mse: 0.7976\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7851 - mse: 0.7851\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7732 - mse: 0.7732\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7614 - mse: 0.7614\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7496 - mse: 0.7496\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7401 - mse: 0.7401\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7304 - mse: 0.7304\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7185 - mse: 0.7185\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7113 - mse: 0.7113\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7013 - mse: 0.7013\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6917 - mse: 0.6917\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6830 - mse: 0.6830\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6741 - mse: 0.6741\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6662 - mse: 0.6662\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6590 - mse: 0.6590\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6508 - mse: 0.6508\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6440 - mse: 0.6440\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6374 - mse: 0.6374\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6303 - mse: 0.6303\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6236 - mse: 0.6236\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6174 - mse: 0.6174\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6118 - mse: 0.6118\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6057 - mse: 0.6057\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5999 - mse: 0.5999\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5946 - mse: 0.5946\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5908 - mse: 0.5908\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5849 - mse: 0.5849\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5799 - mse: 0.5799\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5741 - mse: 0.5741\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5701 - mse: 0.5701\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5651 - mse: 0.5651\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5612 - mse: 0.5612\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5566 - mse: 0.5566\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5529 - mse: 0.5529\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5487 - mse: 0.5487\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - mse: 0.5440\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5410 - mse: 0.5410\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5368 - mse: 0.5368\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5344 - mse: 0.5344\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5307 - mse: 0.5307\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5268 - mse: 0.5268\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5227 - mse: 0.5227\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5207 - mse: 0.5207\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5168 - mse: 0.5168\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5133 - mse: 0.5133\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5107 - mse: 0.5107\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5086 - mse: 0.5086\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5050 - mse: 0.5050\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5019 - mse: 0.5019\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.5000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4968 - mse: 0.4968\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4944 - mse: 0.4944\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4923 - mse: 0.4923\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4893 - mse: 0.4893\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4876 - mse: 0.4876\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4851 - mse: 0.4851\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4832 - mse: 0.4832\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4806 - mse: 0.4806\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4788 - mse: 0.4788\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4774 - mse: 0.4774\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4754 - mse: 0.4754\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4751 - mse: 0.4751\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4754 - mse: 0.4754\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4729 - mse: 0.4729\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4706 - mse: 0.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed079c2760>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128                                                     #指定模型中状态空间的维度\n",
    "inp_img = Input(shape=(dim_img,))                                     #输入层：图像特征向量\n",
    "inp_follower=Input(shape=(1,))                                        #输入层：粉丝数目\n",
    "inp_cap=Input(shape=(dim_cap,))                                       #输入层：描述文本\n",
    "x_img=Dense(hidden_size)(inp_img)                                     #模型处理：图像输入\n",
    "x_follower=Dense(hidden_size)(inp_follower)                           #模型处理：粉丝数目\n",
    "x = Embedding(vocab_size, hidden_size)(inp_cap)                       #模型处理：文本向量化\n",
    "x_cap = LSTM(hidden_size, return_sequences=False)(x)                  #加入一个LSTM网络\n",
    "x=add([x_img,x_follower])                                             #整合不同的输入型号\n",
    "x=Dense(1)(x)                                                         #输出：预测最后的展现量\n",
    "model = Model([inp_img,inp_follower], x)                              #模型整合\n",
    "model.summary()                                                       #打印网络模型摘要表\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['mse'])           #设计优化方案\n",
    "model.fit([imgs,followers], views, epochs=100, batch_size=1000)       #小批次样本量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考：如何做得更好？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
